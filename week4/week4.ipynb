{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Introduction to Data Science 2025\n",
        "\n",
        "# Week 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this week's exercise, we look at prompting and zero- and few-shot task settings. Below is a text generation example from https://github.com/TurkuNLP/intro-to-nlp/blob/master/text_generation_pipeline_example.ipynb demonstrating how to load a text generation pipeline with a pre-trained model and generate text with a given prompt. Your task is to load a similar pre-trained generative model and assess whether the model succeeds at a set of tasks in zero-shot, one-shot, and two-shot settings.\n",
        "\n",
        "**Note: Downloading and running the pre-trained model locally may take some time. Alternatively, you can open and run this notebook on [Google Colab](https://colab.research.google.com/), as assumed in the following example.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIQ1s96UCcJW"
      },
      "source": [
        "## Text generation example\n",
        "\n",
        "This is a brief example of how to run text generation with a causal language model and `pipeline`.\n",
        "\n",
        "Install [transformers](https://huggingface.co/docs/transformers/index) python package. This will be used to load the model and tokenizer and to run generation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4fUBJmXHCHw-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^C\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in c:\\users\\eetos\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.8.0)\n",
            "Collecting torchvision\n",
            "  Downloading torchvision-0.23.0-cp310-cp310-win_amd64.whl.metadata (6.1 kB)\n",
            "Collecting torchaudio\n",
            "  Downloading torchaudio-2.8.0-cp310-cp310-win_amd64.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: filelock in c:\\users\\eetos\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\eetos\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\eetos\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx in c:\\users\\eetos\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\eetos\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in c:\\users\\eetos\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (2025.9.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\eetos\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (2.2.6)\n",
            "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision)\n",
            "  Downloading pillow-11.3.0-cp310-cp310-win_amd64.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\eetos\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\eetos\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading torchvision-0.23.0-cp310-cp310-win_amd64.whl (1.6 MB)\n",
            "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
            "   ------ --------------------------------- 0.3/1.6 MB ? eta -:--:--\n",
            "   ------------- -------------------------- 0.5/1.6 MB 1.3 MB/s eta 0:00:01\n",
            "   -------------------------- ------------- 1.0/1.6 MB 1.3 MB/s eta 0:00:01\n",
            "   -------------------------- ------------- 1.0/1.6 MB 1.3 MB/s eta 0:00:01\n",
            "   -------------------------------- ------- 1.3/1.6 MB 1.3 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 1.6/1.6 MB 1.2 MB/s  0:00:01\n",
            "Downloading torchaudio-2.8.0-cp310-cp310-win_amd64.whl (2.5 MB)\n",
            "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
            "   ---- ----------------------------------- 0.3/2.5 MB ? eta -:--:--\n",
            "   -------- ------------------------------- 0.5/2.5 MB 1.2 MB/s eta 0:00:02\n",
            "   ------------ --------------------------- 0.8/2.5 MB 1.2 MB/s eta 0:00:02\n",
            "   ---------------- ----------------------- 1.0/2.5 MB 1.2 MB/s eta 0:00:02\n",
            "   -------------------- ------------------- 1.3/2.5 MB 1.2 MB/s eta 0:00:01\n",
            "   -------------------- ------------------- 1.3/2.5 MB 1.2 MB/s eta 0:00:01\n",
            "   ----------------------------- ---------- 1.8/2.5 MB 1.2 MB/s eta 0:00:01\n",
            "   ----------------------------- ---------- 1.8/2.5 MB 1.2 MB/s eta 0:00:01\n",
            "   --------------------------------- ------ 2.1/2.5 MB 1.2 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 2.5/2.5 MB 1.2 MB/s  0:00:02\n",
            "Downloading pillow-11.3.0-cp310-cp310-win_amd64.whl (7.0 MB)\n",
            "   ---------------------------------------- 0.0/7.0 MB ? eta -:--:--\n",
            "   - -------------------------------------- 0.3/7.0 MB ? eta -:--:--\n",
            "   --- ------------------------------------ 0.5/7.0 MB 1.2 MB/s eta 0:00:06\n",
            "   ---- ----------------------------------- 0.8/7.0 MB 1.2 MB/s eta 0:00:06\n",
            "   ------ --------------------------------- 1.0/7.0 MB 1.2 MB/s eta 0:00:05\n",
            "   ------ --------------------------------- 1.0/7.0 MB 1.2 MB/s eta 0:00:05\n",
            "   ------- -------------------------------- 1.3/7.0 MB 1.2 MB/s eta 0:00:05\n",
            "   --------- ------------------------------ 1.6/7.0 MB 1.2 MB/s eta 0:00:05\n",
            "   ---------- ----------------------------- 1.8/7.0 MB 1.2 MB/s eta 0:00:05\n",
            "   ------------ --------------------------- 2.1/7.0 MB 1.2 MB/s eta 0:00:05\n",
            "   ------------- -------------------------- 2.4/7.0 MB 1.2 MB/s eta 0:00:04\n",
            "   --------------- ------------------------ 2.6/7.0 MB 1.2 MB/s eta 0:00:04\n",
            "   ---------------- ----------------------- 2.9/7.0 MB 1.2 MB/s eta 0:00:04\n",
            "   ------------------ --------------------- 3.1/7.0 MB 1.2 MB/s eta 0:00:04\n",
            "   ------------------- -------------------- 3.4/7.0 MB 1.2 MB/s eta 0:00:04\n",
            "   --------------------- ------------------ 3.7/7.0 MB 1.2 MB/s eta 0:00:03\n",
            "   ---------------------- ----------------- 3.9/7.0 MB 1.2 MB/s eta 0:00:03\n",
            "   ------------------------ --------------- 4.2/7.0 MB 1.2 MB/s eta 0:00:03\n",
            "   ------------------------- -------------- 4.5/7.0 MB 1.2 MB/s eta 0:00:03\n",
            "   --------------------------- ------------ 4.7/7.0 MB 1.2 MB/s eta 0:00:02\n",
            "   ---------------------------- ----------- 5.0/7.0 MB 1.2 MB/s eta 0:00:02\n",
            "   ------------------------------ --------- 5.2/7.0 MB 1.2 MB/s eta 0:00:02\n",
            "   ------------------------------ --------- 5.2/7.0 MB 1.2 MB/s eta 0:00:02\n",
            "   ------------------------------- -------- 5.5/7.0 MB 1.2 MB/s eta 0:00:02\n",
            "   --------------------------------- ------ 5.8/7.0 MB 1.2 MB/s eta 0:00:02\n",
            "   ---------------------------------- ----- 6.0/7.0 MB 1.2 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 6.3/7.0 MB 1.2 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 6.6/7.0 MB 1.2 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 7.0/7.0 MB 1.2 MB/s  0:00:05\n",
            "Installing collected packages: pillow, torchvision, torchaudio\n",
            "\n",
            "   ---------------------------------------- 0/3 [pillow]\n",
            "   ---------------------------------------- 0/3 [pillow]\n",
            "   ---------------------------------------- 0/3 [pillow]\n",
            "   ---------------------------------------- 0/3 [pillow]\n",
            "   ---------------------------------------- 0/3 [pillow]\n",
            "   ---------------------------------------- 0/3 [pillow]\n",
            "   ---------------------------------------- 0/3 [pillow]\n",
            "   ---------------------------------------- 0/3 [pillow]\n",
            "   ---------------------------------------- 0/3 [pillow]\n",
            "   ---------------------------------------- 0/3 [pillow]\n",
            "   ---------------------------------------- 0/3 [pillow]\n",
            "   ---------------------------------------- 0/3 [pillow]\n",
            "   ---------------------------------------- 0/3 [pillow]\n",
            "   ---------------------------------------- 0/3 [pillow]\n",
            "   ------------- -------------------------- 1/3 [torchvision]\n",
            "   ------------- -------------------------- 1/3 [torchvision]\n",
            "   ------------- -------------------------- 1/3 [torchvision]\n",
            "   ------------- -------------------------- 1/3 [torchvision]\n",
            "   ------------- -------------------------- 1/3 [torchvision]\n",
            "   ------------- -------------------------- 1/3 [torchvision]\n",
            "   ------------- -------------------------- 1/3 [torchvision]\n",
            "   ------------- -------------------------- 1/3 [torchvision]\n",
            "   ------------- -------------------------- 1/3 [torchvision]\n",
            "   ------------- -------------------------- 1/3 [torchvision]\n",
            "   ------------- -------------------------- 1/3 [torchvision]\n",
            "   ------------- -------------------------- 1/3 [torchvision]\n",
            "   ------------- -------------------------- 1/3 [torchvision]\n",
            "   ------------- -------------------------- 1/3 [torchvision]\n",
            "   ------------- -------------------------- 1/3 [torchvision]\n",
            "   ------------- -------------------------- 1/3 [torchvision]\n",
            "   ------------- -------------------------- 1/3 [torchvision]\n",
            "   ------------- -------------------------- 1/3 [torchvision]\n",
            "   ------------- -------------------------- 1/3 [torchvision]\n",
            "   -------------------------- ------------- 2/3 [torchaudio]\n",
            "   -------------------------- ------------- 2/3 [torchaudio]\n",
            "   -------------------------- ------------- 2/3 [torchaudio]\n",
            "   -------------------------- ------------- 2/3 [torchaudio]\n",
            "   -------------------------- ------------- 2/3 [torchaudio]\n",
            "   -------------------------- ------------- 2/3 [torchaudio]\n",
            "   -------------------------- ------------- 2/3 [torchaudio]\n",
            "   -------------------------- ------------- 2/3 [torchaudio]\n",
            "   -------------------------- ------------- 2/3 [torchaudio]\n",
            "   -------------------------- ------------- 2/3 [torchaudio]\n",
            "   -------------------------- ------------- 2/3 [torchaudio]\n",
            "   -------------------------- ------------- 2/3 [torchaudio]\n",
            "   -------------------------- ------------- 2/3 [torchaudio]\n",
            "   ---------------------------------------- 3/3 [torchaudio]\n",
            "\n",
            "Successfully installed pillow-11.3.0 torchaudio-2.8.0 torchvision-0.23.0\n"
          ]
        }
      ],
      "source": [
        "!pip install --quiet transformers\n",
        "!pip install torch torchvision torchaudio\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZRNZgRJCt6Q"
      },
      "source": [
        "Import the `AutoTokenizer`, `AutoModelForCausalLM`, and `pipeline` classes. The first two support loading tokenizers and generative models from the [Hugging Face repository](https://huggingface.co/models), and the last wraps a tokenizer and a model for convenience."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jwyK005xCFSF"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Eetos\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QJPDe3ZC_sL"
      },
      "source": [
        "Load a generative model and its tokenizer. You can substitute any other generative model name here (e.g. [other TurkuNLP GPT-3 models](https://huggingface.co/models?sort=downloads&search=turkunlp%2Fgpt3)), but note that Colab may have issues running larger models. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "wqTxn_QaCNjZ"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Eetos\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Eetos\\.cache\\huggingface\\hub\\models--TurkuNLP--gpt3-finnish-large. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
            "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
            "  warnings.warn(message)\n",
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[4], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m MODEL_NAME \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTurkuNLP/gpt3-finnish-large\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      3\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(MODEL_NAME)\n\u001b[1;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMODEL_NAME\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Eetos\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:604\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    602\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mconfig_class \u001b[38;5;241m==\u001b[39m config\u001b[38;5;241m.\u001b[39msub_configs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext_config\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    603\u001b[0m         config \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mget_text_config()\n\u001b[1;32m--> 604\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m    605\u001b[0m         pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39mmodel_args, config\u001b[38;5;241m=\u001b[39mconfig, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    606\u001b[0m     )\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    609\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    610\u001b[0m )\n",
            "File \u001b[1;32mc:\\Users\\Eetos\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\modeling_utils.py:288\u001b[0m, in \u001b[0;36mrestore_default_dtype.<locals>._wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    286\u001b[0m old_dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mget_default_dtype()\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 288\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    290\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_default_dtype(old_dtype)\n",
            "File \u001b[1;32mc:\\Users\\Eetos\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\modeling_utils.py:5030\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   5020\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   5021\u001b[0m     gguf_file\n\u001b[0;32m   5022\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m device_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   5023\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m ((\u001b[38;5;28misinstance\u001b[39m(device_map, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisk\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m device_map\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisk\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m device_map)\n\u001b[0;32m   5024\u001b[0m ):\n\u001b[0;32m   5025\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   5026\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOne or more modules is configured to be mapped to disk. Disk offload is not supported for models \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   5027\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloaded from GGUF files.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   5028\u001b[0m     )\n\u001b[1;32m-> 5030\u001b[0m checkpoint_files, sharded_metadata \u001b[38;5;241m=\u001b[39m \u001b[43m_get_resolved_checkpoint_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5031\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5032\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5033\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvariant\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvariant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5034\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgguf_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgguf_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5035\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfrom_tf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_tf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5036\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfrom_flax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_flax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5037\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_safetensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_safetensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5038\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5039\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5040\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5041\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5042\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5043\u001b[0m \u001b[43m    \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5044\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5045\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5046\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_auto_class\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   5047\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtransformers_explicit_filename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransformers_explicit_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5048\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5050\u001b[0m is_sharded \u001b[38;5;241m=\u001b[39m sharded_metadata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   5051\u001b[0m is_quantized \u001b[38;5;241m=\u001b[39m hf_quantizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Eetos\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\modeling_utils.py:1179\u001b[0m, in \u001b[0;36m_get_resolved_checkpoint_files\u001b[1;34m(pretrained_model_name_or_path, subfolder, variant, gguf_file, from_tf, from_flax, use_safetensors, cache_dir, force_download, proxies, local_files_only, token, user_agent, revision, commit_hash, is_remote_code, transformers_explicit_filename)\u001b[0m\n\u001b[0;32m   1176\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1177\u001b[0m         \u001b[38;5;66;03m# This repo has no safetensors file of any kind, we switch to PyTorch.\u001b[39;00m\n\u001b[0;32m   1178\u001b[0m         filename \u001b[38;5;241m=\u001b[39m _add_variant(WEIGHTS_NAME, variant)\n\u001b[1;32m-> 1179\u001b[0m         resolved_archive_file \u001b[38;5;241m=\u001b[39m cached_file(\n\u001b[0;32m   1180\u001b[0m             pretrained_model_name_or_path, filename, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcached_file_kwargs\n\u001b[0;32m   1181\u001b[0m         )\n\u001b[0;32m   1182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resolved_archive_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m filename \u001b[38;5;241m==\u001b[39m _add_variant(WEIGHTS_NAME, variant):\n\u001b[0;32m   1183\u001b[0m     \u001b[38;5;66;03m# Maybe the checkpoint is sharded, we try to grab the index name in this case.\u001b[39;00m\n\u001b[0;32m   1184\u001b[0m     resolved_archive_file \u001b[38;5;241m=\u001b[39m cached_file(\n\u001b[0;32m   1185\u001b[0m         pretrained_model_name_or_path,\n\u001b[0;32m   1186\u001b[0m         _add_variant(WEIGHTS_INDEX_NAME, variant),\n\u001b[0;32m   1187\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcached_file_kwargs,\n\u001b[0;32m   1188\u001b[0m     )\n",
            "File \u001b[1;32mc:\\Users\\Eetos\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\utils\\hub.py:321\u001b[0m, in \u001b[0;36mcached_file\u001b[1;34m(path_or_repo_id, filename, **kwargs)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcached_file\u001b[39m(\n\u001b[0;32m    264\u001b[0m     path_or_repo_id: Union[\u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike],\n\u001b[0;32m    265\u001b[0m     filename: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m    266\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    267\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m    268\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;124;03m    Tries to locate a file in a local folder and repo, downloads and cache it if necessary.\u001b[39;00m\n\u001b[0;32m    270\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    319\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[0;32m    320\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 321\u001b[0m     file \u001b[38;5;241m=\u001b[39m cached_files(path_or_repo_id\u001b[38;5;241m=\u001b[39mpath_or_repo_id, filenames\u001b[38;5;241m=\u001b[39m[filename], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    322\u001b[0m     file \u001b[38;5;241m=\u001b[39m file[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m file\n\u001b[0;32m    323\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m file\n",
            "File \u001b[1;32mc:\\Users\\Eetos\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\utils\\hub.py:478\u001b[0m, in \u001b[0;36mcached_files\u001b[1;34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m    475\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    476\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(full_filenames) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    477\u001b[0m         \u001b[38;5;66;03m# This is slightly better for only 1 file\u001b[39;00m\n\u001b[1;32m--> 478\u001b[0m         \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    481\u001b[0m \u001b[43m            \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    482\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    484\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    485\u001b[0m \u001b[43m            \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    486\u001b[0m \u001b[43m            \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    487\u001b[0m \u001b[43m            \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    492\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    493\u001b[0m         snapshot_download(\n\u001b[0;32m    494\u001b[0m             path_or_repo_id,\n\u001b[0;32m    495\u001b[0m             allow_patterns\u001b[38;5;241m=\u001b[39mfull_filenames,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    504\u001b[0m             local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[0;32m    505\u001b[0m         )\n",
            "File \u001b[1;32mc:\\Users\\Eetos\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[0;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\Eetos\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:1010\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[1;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[0;32m    990\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _hf_hub_download_to_local_dir(\n\u001b[0;32m    991\u001b[0m         \u001b[38;5;66;03m# Destination\u001b[39;00m\n\u001b[0;32m    992\u001b[0m         local_dir\u001b[38;5;241m=\u001b[39mlocal_dir,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1007\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[0;32m   1008\u001b[0m     )\n\u001b[0;32m   1009\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1010\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1011\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[0;32m   1012\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1013\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[0;32m   1014\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1015\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1016\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1017\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1018\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[0;32m   1019\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1020\u001b[0m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1021\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1022\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1023\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1024\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[0;32m   1025\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1026\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1027\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Eetos\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:1171\u001b[0m, in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[1;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[0;32m   1168\u001b[0m \u001b[38;5;66;03m# Local file doesn't exist or etag isn't a match => retrieve file from remote (or cache)\u001b[39;00m\n\u001b[0;32m   1170\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m WeakFileLock(lock_path):\n\u001b[1;32m-> 1171\u001b[0m     \u001b[43m_download_to_tmp_and_move\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mincomplete_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.incomplete\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdestination_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1174\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl_to_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1179\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1180\u001b[0m \u001b[43m        \u001b[49m\u001b[43metag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mxet_file_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxet_file_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1182\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1183\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(pointer_path):\n\u001b[0;32m   1184\u001b[0m         _create_symlink(blob_path, pointer_path, new_blob\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "File \u001b[1;32mc:\\Users\\Eetos\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:1738\u001b[0m, in \u001b[0;36m_download_to_tmp_and_move\u001b[1;34m(incomplete_path, destination_path, url_to_download, proxies, headers, expected_size, filename, force_download, etag, xet_file_data)\u001b[0m\n\u001b[0;32m   1731\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m xet_file_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m constants\u001b[38;5;241m.\u001b[39mHF_HUB_DISABLE_XET:\n\u001b[0;32m   1732\u001b[0m             logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m   1733\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mXet Storage is enabled for this repo, but the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhf_xet\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m package is not installed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1734\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFalling back to regular HTTP download. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1735\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1736\u001b[0m             )\n\u001b[1;32m-> 1738\u001b[0m         \u001b[43mhttp_get\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1739\u001b[0m \u001b[43m            \u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1740\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1741\u001b[0m \u001b[43m            \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1742\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresume_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1743\u001b[0m \u001b[43m            \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[43m            \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1745\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1747\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownload complete. Moving file to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdestination_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1748\u001b[0m _chmod_and_move(incomplete_path, destination_path)\n",
            "File \u001b[1;32mc:\\Users\\Eetos\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:496\u001b[0m, in \u001b[0;36mhttp_get\u001b[1;34m(url, temp_file, proxies, resume_size, headers, expected_size, displayed_filename, _nb_retries, _tqdm_bar)\u001b[0m\n\u001b[0;32m    494\u001b[0m new_resume_size \u001b[38;5;241m=\u001b[39m resume_size\n\u001b[0;32m    495\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 496\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m r\u001b[38;5;241m.\u001b[39miter_content(chunk_size\u001b[38;5;241m=\u001b[39mconstants\u001b[38;5;241m.\u001b[39mDOWNLOAD_CHUNK_SIZE):\n\u001b[0;32m    497\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m chunk:  \u001b[38;5;66;03m# filter out keep-alive new chunks\u001b[39;00m\n\u001b[0;32m    498\u001b[0m             progress\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mlen\u001b[39m(chunk))\n",
            "File \u001b[1;32mc:\\Users\\Eetos\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\requests\\models.py:820\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[1;34m()\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    819\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 820\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    822\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
            "File \u001b[1;32mc:\\Users\\Eetos\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\response.py:1091\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[1;34m(self, amt, decode_content)\u001b[0m\n\u001b[0;32m   1089\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1090\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 1091\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1093\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[0;32m   1094\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m data\n",
            "File \u001b[1;32mc:\\Users\\Eetos\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\response.py:980\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[0;32m    977\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m amt:\n\u001b[0;32m    978\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer\u001b[38;5;241m.\u001b[39mget(amt)\n\u001b[1;32m--> 980\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    982\u001b[0m flush_decoder \u001b[38;5;241m=\u001b[39m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data)\n\u001b[0;32m    984\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
            "File \u001b[1;32mc:\\Users\\Eetos\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\response.py:904\u001b[0m, in \u001b[0;36mHTTPResponse._raw_read\u001b[1;34m(self, amt, read1)\u001b[0m\n\u001b[0;32m    901\u001b[0m fp_closed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclosed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    903\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_error_catcher():\n\u001b[1;32m--> 904\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread1\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    905\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[0;32m    906\u001b[0m         \u001b[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001b[39;00m\n\u001b[0;32m    907\u001b[0m         \u001b[38;5;66;03m# Close the connection when no data is returned\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    912\u001b[0m         \u001b[38;5;66;03m# not properly close the connection in all cases. There is\u001b[39;00m\n\u001b[0;32m    913\u001b[0m         \u001b[38;5;66;03m# no harm in redundantly calling close.\u001b[39;00m\n\u001b[0;32m    914\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mclose()\n",
            "File \u001b[1;32mc:\\Users\\Eetos\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\urllib3\\response.py:887\u001b[0m, in \u001b[0;36mHTTPResponse._fp_read\u001b[1;34m(self, amt, read1)\u001b[0m\n\u001b[0;32m    884\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread1(amt) \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread1()\n\u001b[0;32m    885\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    886\u001b[0m     \u001b[38;5;66;03m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[1;32m--> 887\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread()\n",
            "File \u001b[1;32mc:\\Users\\Eetos\\AppData\\Local\\Programs\\Python\\Python310\\lib\\http\\client.py:465\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    462\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[0;32m    463\u001b[0m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[0;32m    464\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength\n\u001b[1;32m--> 465\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    466\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[0;32m    467\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[0;32m    468\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[0;32m    469\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
            "File \u001b[1;32mc:\\Users\\Eetos\\AppData\\Local\\Programs\\Python\\Python310\\lib\\socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 705\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    707\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Eetos\\AppData\\Local\\Programs\\Python\\Python310\\lib\\ssl.py:1273\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1269\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1270\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1271\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1272\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1273\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1274\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1275\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
            "File \u001b[1;32mc:\\Users\\Eetos\\AppData\\Local\\Programs\\Python\\Python310\\lib\\ssl.py:1129\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1128\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1129\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1130\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1131\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "MODEL_NAME = 'TurkuNLP/gpt3-finnish-large'\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ADWWb77e1sY"
      },
      "source": [
        "Instantiate a text generation pipeline using the tokenizer and model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "0IIJzNrEe5qx"
      },
      "outputs": [],
      "source": [
        "pipe = pipeline(\n",
        "    'text-generation',\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    device=model.device\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAohNr1ciwaU"
      },
      "source": [
        "We can now call the pipeline with a text prompt; it will take care of tokenizing, encoding, generation, and decoding:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWcOJkiKi5vr",
        "outputId": "11cb09ab-310d-438e-e372-ef8d7f8f66a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'generated_text': 'Terve, miten menee?”\\n”Hyvin, kiitos.”\\n”Kiva kuulla.”\\n”Kuule, minulla on sinulle asiaa.”\\n'}]\n"
          ]
        }
      ],
      "source": [
        "output = pipe('Terve, miten menee?', max_new_tokens=25)\n",
        "\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNRMsxXOjSo0"
      },
      "source": [
        "Just print the text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Op7MJ6XjahG",
        "outputId": "5d9e26dd-3e80-4663-a712-d85093fad073"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Terve, miten menee?”\n",
            "”Hyvin, kiitos.”\n",
            "”Kiva kuulla.”\n",
            "”Kuule, minulla on sinulle asiaa.”\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(output[0]['generated_text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YROp3hyikXPO"
      },
      "source": [
        "We can also call the pipeline with any arguments that the model `generate` function supports. For details on text generation using `transformers`, see e.g. [this tutorial](https://huggingface.co/blog/how-to-generate).\n",
        "\n",
        "Example with sampling and a high `temperature` parameter to generate more chaotic output:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22QjXE88jkim",
        "outputId": "372a4fc2-e305-4034-cea3-a52b6103c24f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Terve, miten menee? kysyi Heikki yhtäkkiä astuessaan taloon sisään kantaen kahvipöytä-tarvikkeita käsissään sisään tultuaan.\n",
            "(Ryökäle luuli varmasti hänen tulevan meille istumaan)\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "output = pipe(\n",
        "    'Terve, miten menee?',\n",
        "    do_sample=True,\n",
        "    temperature=10.0,\n",
        "    max_new_tokens=25\n",
        ")\n",
        "\n",
        "print(output[0]['generated_text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise 1\n",
        "\n",
        "Your task is to assess whether a generative model succeeds in the following tasks in zero-shot, one-shot, and two-shot settings:\n",
        "\n",
        "- binary sentiment classification (positive / negative)\n",
        "\n",
        "- person name recognition\n",
        "\n",
        "- two-digit addition (e.g. 11 + 22 = 33)\n",
        "\n",
        "For example, for assessing whether a generative model can name capital cities, we could use the following prompts:\n",
        "\n",
        "- zero-shot:\n",
        "\t>\"\"\"\\\n",
        "\t>Identify the capital cities of countries.\n",
        "\t>\n",
        "\t>Question: What is the capital of Finland?\\\n",
        "\t>Answer:\\\n",
        "\t>\"\"\"\n",
        "- one-shot:\n",
        "\t>\"\"\"\\\n",
        "\t>Identify the capital cities of countries.\n",
        "\t>\n",
        "\t>Question: What is the capital of Sweden?\\\n",
        "\t>Answer: Stockholm\n",
        "\t>\n",
        "\t>Question: What is the capital of Finland?\\\n",
        "\t>Answer:\\\n",
        "\t>\"\"\"\n",
        "- two-shot:\n",
        "\t>\"\"\"\\\n",
        "\t>Identify the capital cities of countries.\n",
        "\t>\n",
        "\t>Question: What is the capital of Sweden?\\\n",
        "\t>Answer: Stockholm\n",
        "\t>\n",
        "\t>Question: What is the capital of Denmark?\\\n",
        "\t>Answer: Copenhagen\n",
        "\t>\n",
        "\t>Question: What is the capital of Finland?\\\n",
        "\t>Answer:\\\n",
        "\t>\"\"\"\n",
        "\n",
        "You can do the tasks either in English or Finnish and use a generative model of your choice from the Hugging Face models repository, for example the following models:\n",
        "\n",
        "- English: `gpt2-large`\n",
        "- Finnish: `TurkuNLP/gpt3-finnish-large`\n",
        "\n",
        "You can either come up with your own instructions for the tasks or use the following:\n",
        "\n",
        "- English:\n",
        "\t- binary sentiment classification: \"Do the following texts express a positive or negative sentiment?\"\n",
        "\t- person name recognition: \"List the person names occurring in the following texts.\"\n",
        "\t- two-digit addition: \"This is a first grade math exam.\"\n",
        "- Finnish:\n",
        "\t- binary sentiment classification: \"Ilmaisevatko seuraavat tekstit positiivista vai negatiivista tunnetta?\"\n",
        "\t- person name recognition: \"Listaa seuraavissa teksteissä mainitut henkilönnimet.\"\n",
        "\t- two-digit addition: \"Tämä on ensimmäisen luokan matematiikan koe.\"\n",
        "\n",
        "Come up with at least two test cases for each of the three tasks, and come up with your own one- and two-shot examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SENTIMENT\n",
            "zero\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'pipe' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[9], line 51\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(shot)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, prompt \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(examples, \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m---> 51\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mpipe\u001b[49m(prompt, max_new_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m output: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenerated_text\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[1;31mNameError\u001b[0m: name 'pipe' is not defined"
          ]
        }
      ],
      "source": [
        "prompts = {\n",
        "    \"sentiment\": {\n",
        "        \"zero\": [\n",
        "            'Do the following texts express a positive or negative sentiment?\\n\\nText: \"I love this movie!\"\\nAnswer:',\n",
        "            'Do the following texts express a positive or negative sentiment?\\n\\nText: \"He makes me mad.\"\\nAnswer:'\n",
        "        ],\n",
        "        \"one\": [\n",
        "            'Do the following texts express a positive or negative sentiment?\\n\\nText: \"I hate rock music.\"\\nAnswer: Negative\\n\\nText: \"I love this movie!\"\\nAnswer:',\n",
        "            'Do the following texts express a positive or negative sentiment?\\n\\nText: \"The food was terrible.\"\\nAnswer: Negative\\n\\nText: \"I enjoyed my stay!\"\\nAnswer:'\n",
        "        ],\n",
        "        \"two\": [\n",
        "            'Do the following texts express a positive or negative sentiment?\\n\\nText: \"I hate traffic jams.\"\\nAnswer: Negative\\n\\nText: \"The food was amazing.\"\\nAnswer: Positive\\n\\nText: \"I love this movie!\"\\nAnswer:',\n",
        "            'Do the following texts express a positive or negative sentiment?\\n\\nText: \"The food was bland.\"\\nAnswer: Negative\\n\\nText: \"The staff were very friendly.\"\\nAnswer: Positive\\n\\nText: \"I enjoyed the concert a lot!\"\\nAnswer:'\n",
        "        ]\n",
        "    },\n",
        "    \"names\": {\n",
        "        \"zero\": [\n",
        "            'List the person names occurring in the following text:\\n\\nText: \"Bob and Patrick are best friends.\"\\nAnswer:',\n",
        "            'List the person names occurring in the following text:\\n\\nText: \"Emmy and Sarah were here.\"\\nAnswer:'\n",
        "        ],\n",
        "        \"one\": [\n",
        "            'List the person names occurring in the following text:\\n\\nText: \"John and Mary are classmates.\"\\nAnswer: John, Mary\\n\\nText: \"Alice and Bob went to the park.\"\\nAnswer:',\n",
        "            'List the person names occurring in the following text:\\n\\nText: \"Emma, Olivia, and Liam are siblings.\"\\nAnswer: Emma, Olivia, Liam\\n\\nText: \"Michael and Sarah attended the meeting.\"\\nAnswer:'\n",
        "        ],\n",
        "        \"two\": [\n",
        "            'List the person names occurring in the following text:\\n\\nText: \"Bob and Patrick are best friends.\"\\nAnswer: Bob, Patrick\\n\\nText: \"Tom and Jerry are friends.\"\\nAnswer: Tom, Jerry\\n\\nText: \"Alice and Bob went to the park.\"\\nAnswer:',\n",
        "            'List the person names occurring in the following text:\\n\\nText: \"Eetos and Uljas are siblings.\"\\nAnswer: Eetos, Uljas\\n\\nText: \"Sara and Sera went to school.\"\\nAnswer: Sara, Seraw\\n\\nText: \"Michael and Sarah attended the meeting.\"\\nAnswer:'\n",
        "        ]\n",
        "    },\n",
        "    \"addition\": {\n",
        "        \"zero\": [\n",
        "            'This is a first grade math exam.\\n\\nWhat is 9 + 10?\\nAnswer:',\n",
        "            'This is a first grade math exam.\\n\\nWhat is 420 + 69?\\nAnswer:'\n",
        "        ],\n",
        "        \"one\": [\n",
        "            'This is a first grade math exam.\\n\\nWhat is 666 + 69?\\nAnswer: 735\\n\\nWhat is 11 + 22?\\nAnswer:',\n",
        "            'This is a first grade math exam.\\n\\nWhat is 11 + 22?\\nAnswer: 33\\n\\nWhat is 17 + 28?\\nAnswer:'\n",
        "        ],\n",
        "        \"two\": [\n",
        "            'This is a first grade math exam.\\n\\nWhat is 41 + 22?\\nAnswer: 63\\n\\nWhat is 23 + 45?\\nAnswer: 68\\n\\nWhat is 11 + 22?\\nAnswer:',\n",
        "            'This is a first grade math exam.\\n\\nWhat is 14 + 14?\\nAnswer: 28\\n\\nWhat is 21 + 33?\\nAnswer: 54\\n\\nWhat is 17 + 28?\\nAnswer:'\n",
        "        ]\n",
        "    }\n",
        "}\n",
        "\n",
        "for task, settings in prompts.items():\n",
        "    print(task.upper())\n",
        "    for shot, examples in settings.items():\n",
        "        print(shot)\n",
        "        for i, prompt in enumerate(examples, 1):\n",
        "            output = pipe(prompt, max_new_tokens=20)\n",
        "            print(f\"Test{i} output: {output[0]['generated_text']}\")\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "SENTIMENT\n",
        "zero\n",
        "\n",
        "\n",
        "\n",
        "Test1 output: Do the following texts express a positive or negative sentiment?\n",
        "\n",
        "Text: \"I love this movie!\"\n",
        "Answer: \"Yes! I love this movie!\"\n",
        "\n",
        "Text: \"I was shocked by this movie!\"\n",
        "\n",
        "\n",
        "\n",
        "Test2 output: Do the following texts express a positive or negative sentiment?\n",
        "\n",
        "Text: \"He makes me mad.\"\n",
        "Answer: \"He makes me mad.\"\n",
        "\n",
        "Text: \"He makes me mad.\"\n",
        "\n",
        "Answer:\n",
        "one\n",
        "\n",
        "\n",
        "Test1 output: Do the following texts express a positive or negative sentiment?\n",
        "\n",
        "Text: \"I hate rock music.\"\n",
        "Answer: Negative\n",
        "\n",
        "Text: \"I love this movie!\"\n",
        "Answer: Positive\n",
        "\n",
        "Text: \"I love this book!\"\n",
        "\n",
        "Answer: Positive\n",
        "\n",
        "Text:\n",
        "\n",
        "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
        "\n",
        "Test2 output: Do the following texts express a positive or negative sentiment?\n",
        "\n",
        "Text: \"The food was terrible.\"\n",
        "Answer: Negative\n",
        "\n",
        "Text: \"I enjoyed my stay!\"\n",
        "Answer: Positive\n",
        "\n",
        "Text: \"I will miss this place. Thank you for all the fun we had\n",
        "two\n",
        "\n",
        "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
        "\n",
        "Test1 output: Do the following texts express a positive or negative sentiment?\n",
        "\n",
        "Text: \"I hate traffic jams.\"\n",
        "Answer: Negative\n",
        "\n",
        "Text: \"The food was amazing.\"\n",
        "Answer: Positive\n",
        "\n",
        "Text: \"I love this movie!\"\n",
        "Answer: Positive\n",
        "\n",
        "Text: \"I hate traffic jams.\"\n",
        "\n",
        "Answer: Negative\n",
        "\n",
        "Text:\n",
        "\n",
        "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
        "\n",
        "Test2 output: Do the following texts express a positive or negative sentiment?\n",
        "\n",
        "Text: \"The food was bland.\"\n",
        "Answer: Negative\n",
        "\n",
        "Text: \"The staff were very friendly.\"\n",
        "Answer: Positive\n",
        "\n",
        "Text: \"I enjoyed the concert a lot!\"\n",
        "Answer: Negative\n",
        "\n",
        "Text: \"I wish I had the opportunity to go again!\"\n",
        "\n",
        "Answer:\n",
        "NAMES\n",
        "zero\n",
        "\n",
        "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
        "\n",
        "Test1 output: List the person names occurring in the following text:\n",
        "\n",
        "Text: \"Bob and Patrick are best friends.\"\n",
        "Answer: \"Bob and Patrick are best friends.\"\n",
        "\n",
        "Text: \"Bob and Patty are best friends.\"\n",
        "\n",
        "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
        "\n",
        "Test2 output: List the person names occurring in the following text:\n",
        "\n",
        "Text: \"Emmy and Sarah were here.\"\n",
        "Answer: \"Emmy and Sarah were here.\"\n",
        "\n",
        "The text above is the same as this:\n",
        "\n",
        "one\n",
        "\n",
        "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
        "\n",
        "Test1 output: List the person names occurring in the following text:\n",
        "\n",
        "Text: \"John and Mary are classmates.\"\n",
        "Answer: John, Mary\n",
        "\n",
        "Text: \"Alice and Bob went to the park.\"\n",
        "Answer: Alice and Bob\n",
        "\n",
        "Text: \"They went to the park to have a picnic.\" Answer:\n",
        "\n",
        "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
        "\n",
        "Test2 output: List the person names occurring in the following text:\n",
        "\n",
        "Text: \"Emma, Olivia, and Liam are siblings.\"\n",
        "Answer: Emma, Olivia, Liam\n",
        "\n",
        "Text: \"Michael and Sarah attended the meeting.\"\n",
        "Answer: Michael and Sarah\n",
        "\n",
        "Text: \"Emma and Liam attended the meeting.\"\n",
        "\n",
        "Answer:\n",
        "two\n",
        "\n",
        "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
        "\n",
        "Test1 output: List the person names occurring in the following text:\n",
        "\n",
        "Text: \"Bob and Patrick are best friends.\"\n",
        "Answer: Bob, Patrick\n",
        "\n",
        "Text: \"Tom and Jerry are friends.\"\n",
        "Answer: Tom, Jerry\n",
        "\n",
        "Text: \"Alice and Bob went to the park.\"\n",
        "Answer: Alice\n",
        "\n",
        "Text: \"Alice and Bob went to the park.\"\n",
        "\n",
        "Answer: Alice\n",
        "\n",
        "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
        "\n",
        "Test2 output: List the person names occurring in the following text:\n",
        "\n",
        "Text: \"Eetos and Uljas are siblings.\"\n",
        "Answer: Eetos, Uljas\n",
        "\n",
        "Text: \"Sara and Sera went to school.\"\n",
        "Answer: Sara, Seraw\n",
        "\n",
        "Text: \"Michael and Sarah attended the meeting.\"\n",
        "Answer: Michael, Sarah,\n",
        "\n",
        "ADDITION\n",
        "zero\n",
        "\n",
        "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
        "\n",
        "Test1 output: This is a first grade math exam.\n",
        "\n",
        "What is 9 + 10?\n",
        "Answer:\n",
        "\n",
        "9\n",
        "\n",
        "10\n",
        "\n",
        "10\n",
        "\n",
        "10\n",
        "\n",
        "10\n",
        "\n",
        "10\n",
        "\n",
        "\n",
        "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
        "\n",
        "Test2 output: This is a first grade math exam.\n",
        "\n",
        "What is 420 + 69?\n",
        "Answer: 420 + 69 = 420.\n",
        "\n",
        "What is the difference between 420 and 69?\n",
        "\n",
        "Answer\n",
        "one\n",
        "\n",
        "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
        "\n",
        "Test1 output: This is a first grade math exam.\n",
        "\n",
        "What is 666 + 69?\n",
        "Answer: 735\n",
        "\n",
        "What is 11 + 22?\n",
        "Answer: 2\n",
        "\n",
        "What is 666 + 7?\n",
        "\n",
        "Answer: 7\n",
        "\n",
        "What is 2 +\n",
        "\n",
        "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
        "\n",
        "Test2 output: This is a first grade math exam.\n",
        "\n",
        "What is 11 + 22?\n",
        "Answer: 33\n",
        "\n",
        "What is 17 + 28?\n",
        "Answer: 40\n",
        "\n",
        "What is 12 + 14?\n",
        "\n",
        "Answer: 17\n",
        "\n",
        "What is 6 +\n",
        "two\n",
        "\n",
        "\n",
        "Test1 output: This is a first grade math exam.\n",
        "\n",
        "What is 41 + 22?\n",
        "Answer: 63\n",
        "\n",
        "What is 23 + 45?\n",
        "Answer: 68\n",
        "\n",
        "What is 11 + 22?\n",
        "Answer: 33\n",
        "\n",
        "What is 19 + 5?\n",
        "\n",
        "Answer: 19\n",
        "\n",
        "What is 4 +\n",
        "Test2 output: This is a first grade math exam.\n",
        "\n",
        "What is 14 + 14?\n",
        "Answer: 28\n",
        "\n",
        "What is 21 + 33?\n",
        "Answer: 54\n",
        "\n",
        "What is 17 + 28?\n",
        "Answer: 27\n",
        "\n",
        "What is 8 + 5?\n",
        "\n",
        "Answer: 19\n",
        "\n",
        "What is 10 +\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Submit this exercise by submitting your code and your answers to the above questions as comments on the MOOC platform. You can return this Jupyter notebook (.ipynb) or .py, .R, etc depending on your programming preferences.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMPTKW2dgboQJpXpHYIBCHp",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
